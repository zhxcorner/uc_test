# kfold_generator.py
import os
import pickle
from sklearn.model_selection import StratifiedKFold
from collections import defaultdict
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import torch


# è‡ªå®šä¹‰ Datasetï¼ˆç”¨äºè®¡ç®— mean/stdï¼‰
class ImagePathDataset(Dataset):
    def __init__(self, image_paths, transform=None):
        self.image_paths = image_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        path = self.image_paths[idx]
        img = Image.open(path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img


def compute_mean_std_from_paths(image_paths, batch_size=64, num_workers=4):
    """
    ç»™å®šå›¾åƒè·¯å¾„åˆ—è¡¨ï¼Œè®¡ç®— mean å’Œ std
    """
    if len(image_paths) == 0:
        raise ValueError("No images provided for mean/std calculation")

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])

    dataset = ImagePathDataset(image_paths, transform=transform)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    mean = torch.zeros(3)
    std = torch.zeros(3)
    total_images = 0

    with torch.no_grad():
        for images in loader:
            batch_size = images.size(0)
            mean += images.mean(dim=[0, 2, 3]) * batch_size
            std += images.std(dim=[0, 2, 3]) * batch_size
            total_images += batch_size

    mean /= total_images
    std /= total_images

    return mean.tolist(), std.tolist()


def generate_kfold_path_splits_with_stats(dataset_root, k=5, shuffle=True, random_state=42, save_path='kfold_splits.pkl'):
    """
    ç”Ÿæˆ K-Fold åˆ’åˆ†ï¼Œå¹¶ä¸ºæ¯æŠ˜è®¡ç®—è®­ç»ƒé›†çš„ mean å’Œ std
    âœ… æ‰€æœ‰è·¯å¾„ä¿å­˜ä¸ºç›¸å¯¹äº dataset_root çš„æ ¼å¼ï¼ˆå¦‚ 'LGUC/img1.jpg'ï¼‰
    """
    print(f"ğŸ” æ‰«ææ•°æ®é›†ç›®å½•: {dataset_root}")

    if not os.path.exists(dataset_root):
        raise FileNotFoundError(f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_root}")

    image_paths = []
    labels = []
    class_to_idx = {}

    # æ”¯æŒçš„å›¾åƒæ ¼å¼
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.gif'}

    # è·å–æ‰€æœ‰ç±»åˆ«ï¼ˆå­æ–‡ä»¶å¤¹ï¼‰ï¼Œæ’åºç¡®ä¿é¡ºåºå›ºå®š
    classes = sorted([d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))])
    if len(classes) == 0:
        raise ValueError(f"åœ¨ {dataset_root} ä¸­æœªæ‰¾åˆ°ä»»ä½•ç±»åˆ«æ–‡ä»¶å¤¹")

    class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}

    print(f"ğŸ“Š æ‰¾åˆ° {len(classes)} ä¸ªç±»åˆ«: {classes}")

    # éå†æ¯ä¸ªç±»åˆ«ï¼Œæ”¶é›†å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
    for class_name in classes:
        class_dir = os.path.join(dataset_root, class_name)
        img_count = 0

        for fname in sorted(os.listdir(class_dir)):
            ext = os.path.splitext(fname.lower())[-1]
            if ext in image_extensions:
                abs_path = os.path.join(class_dir, fname)
                if os.path.isfile(abs_path):
                    image_paths.append(abs_path)
                    labels.append(class_name)
                    img_count += 1

        print(f"ğŸ“ {class_name}: {img_count} å¼ å›¾åƒ")

    if len(image_paths) == 0:
        raise ValueError("æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")

    print(f"âœ… å…±æ”¶é›†åˆ° {len(image_paths)} å¼ å›¾åƒï¼Œå¼€å§‹ç”Ÿæˆ {k}-Fold åˆ’åˆ†...")

    # ä½¿ç”¨åˆ†å±‚ K æŠ˜
    skf = StratifiedKFold(n_splits=k, shuffle=shuffle, random_state=random_state)
    fold_splits = []

    # ç”Ÿæˆæ¯ä¸€æŠ˜
    for fold, (train_idx, val_idx) in enumerate(skf.split(image_paths, labels)):
        train_abs_paths = [image_paths[i] for i in train_idx]
        val_abs_paths = [image_paths[i] for i in val_idx]

        # è®¡ç®—è¯¥ fold è®­ç»ƒé›†çš„ mean å’Œ std
        print(f"Fold {fold + 1}/{k}: æ­£åœ¨è®¡ç®—è®­ç»ƒé›† mean/std...")
        mean, std = compute_mean_std_from_paths(train_abs_paths)

        # âœ… è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
        train_rel_paths = [
            os.path.relpath(p, dataset_root).replace("\\", "/") for p in train_abs_paths
        ]
        val_rel_paths = [
            os.path.relpath(p, dataset_root).replace("\\", "/") for p in val_abs_paths
        ]

        fold_splits.append({
            'train': train_rel_paths,  # âœ… ä¿å­˜ç›¸å¯¹è·¯å¾„
            'val': val_rel_paths,     # âœ… ä¿å­˜ç›¸å¯¹è·¯å¾„
            'mean': mean,
            'std': std
        })

        # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
        train_counter = defaultdict(int)
        val_counter = defaultdict(int)
        for i in train_idx:
            train_counter[labels[i]] += 1
        for i in val_idx:
            val_counter[labels[i]] += 1

        print(f"\nğŸ“Œ Fold {fold + 1}/{k} ç±»åˆ«åˆ†å¸ƒ:")
        print(f"{'ç±»åˆ«':<15} {'è®­ç»ƒæ•°':<8} {'éªŒè¯æ•°':<8}")
        print("-" * 35)
        for cls in classes:
            t = train_counter[cls]
            v = val_counter[cls]
            print(f"{cls:<15} {t:<8} {v:<8}")
        print(f"{'æ€»è®¡':<15} {sum(train_counter.values()):<8} {sum(val_counter.values()):<8}")
        print(f"ğŸ“Œ è®¡ç®—å¾—åˆ°çš„å½’ä¸€åŒ–å‚æ•°: mean={mean}, std={std}\n")

    # ä¿å­˜æ‰€æœ‰ä¿¡æ¯
    with open(save_path, 'wb') as f:
        pickle.dump({
            'splits': fold_splits,
            'classes': classes,
            'class_to_idx': class_to_idx,
            'k': k,
            'random_state': random_state,
            'shuffle': shuffle,
            'dataset_root': dataset_root  # ä»ä¿å­˜åŸå§‹è·¯å¾„ä¿¡æ¯ç”¨äºè°ƒè¯•
        }, f)

    print(f"\nğŸ‰ K-Fold åˆ’åˆ†å®Œæˆï¼")
    print(f"ğŸ“Œ åˆ’åˆ†ç»“æœå·²ä¿å­˜è‡³: {save_path}")
    print(f"ğŸ“Œ âœ… æ‰€æœ‰å›¾åƒè·¯å¾„å·²ä¿å­˜ä¸ºç›¸å¯¹äº '{dataset_root}' çš„æ ¼å¼ï¼ˆå¦‚ 'LGUC/img.jpg'ï¼‰")
    print(f"ğŸ“Œ åç»­è®­ç»ƒæ—¶ï¼Œè¯·ä½¿ç”¨ os.path.join(dataset_root, rel_path) æ‹¼æ¥å®Œæ•´è·¯å¾„")


# ================================
# ä½¿ç”¨ç¤ºä¾‹
# ================================
if __name__ == "__main__":
    DATASET_ROOT = "bloodmnist_kfold"  # ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„ï¼Œæ”¯æŒç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„
    SAVE_PATH = "bloodmnist_kfold/kfold_splits.pkl"
    K_FOLDS = 5
    RANDOM_STATE = 42

    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)

    generate_kfold_path_splits_with_stats(
        dataset_root=DATASET_ROOT,
        k=K_FOLDS,
        shuffle=True,
        random_state=RANDOM_STATE,
        save_path=SAVE_PATH
    )