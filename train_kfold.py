# -*- coding: utf-8 -*-
import os
import sys
import json
import logging
import time
import argparse
import torch
import torch.nn as nn
from torchvision import transforms, datasets
import torch.optim as optim
from tqdm import tqdm
from torch.utils.data import DataLoader, Subset
import random
import numpy as np
from collections import defaultdict
import pickle
# åŠ¨æ€å¯¼å…¥æ¨¡åž‹
from MedMamba import VSSM as vssm
from MedMamba import VSSMEdgeEnhanced as edge_enhanced
from MedMamba import DualBranchVSSM as dual_branch
from MedMamba import DualBranchVSSMEnhanced as dual_branch_enhanced

# æ¨¡åž‹å­—å…¸
MODEL_MAP = {
    'vssm': vssm,
    'edge_enhanced': edge_enhanced,
    'dual_branch': dual_branch,
    'dual_branch_enhanced': dual_branch_enhanced,
}

# ========== Utils ==========
def seed_everything(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def setup_logger_and_saver(model_name="UC"):
    current_time = time.strftime("%Y%m%d-%H%M%S")
    log_dir = os.path.join("../logs", current_time)
    os.makedirs(log_dir, exist_ok=True)

    log_file = os.path.join(log_dir, "log.txt")
    model_save_path = os.path.join(log_dir, f"{model_name}Net_best.pth")

    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s][%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )

    logging.info(f"Logging to: {log_file}")
    logging.info(f"Best model will be saved to: {model_save_path}")

    return log_dir, model_save_path


@torch.no_grad()
def evaluate_with_metrics(model, loader, device, num_classes):
    """
    å¤šæŒ‡æ ‡è¯„ä¼°ï¼šAccuracy, Precision, Recall, F1 (weighted)
    """
    model.eval()
    all_preds = []
    all_labels = []

    pbar = tqdm(loader, desc="Evaluating", leave=False, file=sys.stdout)
    for images, labels in pbar:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        preds = outputs.argmax(dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)

    from sklearn.metrics import accuracy_score, precision_recall_fscore_support

    acc = accuracy_score(all_labels, all_preds)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_labels, all_preds, average='weighted', zero_division=0
    )

    return {
        'acc': acc,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }


# ========== Main ==========
def main():
    parser = argparse.ArgumentParser(description="Train MedMamba Model with Model Selection and Edge Fusion Options")
    parser.add_argument('--model_type', type=str, required=True,
                        choices=['vssm', 'edge_enhanced', 'dual_branch', 'dual_branch_enhanced'],
                        help='Type of model to use')
    parser.add_argument('--num_classes', type=int, default=2,
                        help='Number of output classes (default: 2)')
    parser.add_argument('--model_name', type=str, default='UC',
                        help='Model name for saving (default: UC)')

    # è¾¹ç¼˜å¢žå¼ºç›¸å…³å‚æ•°
    parser.add_argument('--edge_layer_idx', type=int, default=0,
                        help='Index of the edge extraction layer (default: 0)')
    parser.add_argument('--fusion_levels', nargs='+', type=int, default=[1, 2],
                        help='List of levels to fuse edge features (default: [1, 2])')
    parser.add_argument('--edge_attention', type=str, default='none',
                        choices=['none', 'se', 'cbam'],
                        help='Type of attention used in edge fusion (default: none)')
    parser.add_argument('--fusion_mode', type=str, default='concat',
                        choices=['concat', 'gate', 'dual'],
                        help='Fusion method to use in edge fusion module (default: concat)')
    parser.add_argument('--dataset', type=str, default='å•ä¸ªç»†èƒžåˆ†ç±»æ•°æ®é›†äºŒåˆ†ç±»S2L')
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--seed', type=int, default=42)

    args = parser.parse_args()
    seed_everything(args.seed)

    # æ—¥å¿—ä¸Žä¿å­˜
    log_dir, base_save_path = setup_logger_and_saver(args.model_name)
    config_path = os.path.join(log_dir, "config.json")
    with open(config_path, 'w') as f:
        json.dump(vars(args), f, indent=4)
    logging.info(f"Training parameters saved to: {config_path}")

    # è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # æ•°æ®é›†è·¯å¾„
    dataset_root = f"/data/{args.dataset}"
    full_dataset = datasets.ImageFolder(root=dataset_root, transform=None)
    logging.info(f"Loaded dataset from: {dataset_root}, total samples: {len(full_dataset)}")

    # ================================
    # ðŸš€ åŠ è½½ kfold_splits.pklï¼ˆåŒ…å« mean/std å’Œç›¸å¯¹è·¯å¾„ï¼‰
    # ================================
    kfold_pkl_path = os.path.join(dataset_root, "kfold_splits.pkl")
    if not os.path.exists(kfold_pkl_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°åˆ’åˆ†æ–‡ä»¶: {kfold_pkl_path}\nè¯·å…ˆè¿è¡Œåˆ’åˆ†ç”Ÿæˆè„šæœ¬ã€‚")

    logging.info(f"âœ… åŠ è½½åˆ’åˆ†æ–‡ä»¶: {kfold_pkl_path}")
    with open(kfold_pkl_path, 'rb') as f:
        data = pickle.load(f)

    splits = data['splits']
    fold_data = []

    # æž„å»ºå®Œæ•´è·¯å¾„ â†’ ç´¢å¼• æ˜ å°„
    path_to_idx = {
        os.path.join(dataset_root, img_path).replace("\\", "/").replace("//", "/"): idx
        for idx, (img_path, _) in enumerate(full_dataset.imgs)
    }

    for fold_idx, split in enumerate(splits):
        rel_train_paths = split['train']
        rel_val_paths = split['val']
        mean = split['mean']
        std = split['std']

        # æ‹¼æŽ¥å®Œæ•´è·¯å¾„
        full_train_paths = [
            os.path.join(dataset_root, p).replace("\\", "/") for p in rel_train_paths
        ]
        full_val_paths = [
            os.path.join(dataset_root, p).replace("\\", "/") for p in rel_val_paths
        ]

        # æ˜ å°„åˆ°ç´¢å¼•
        train_idx = [path_to_idx[p] for p in full_train_paths if p in path_to_idx]
        val_idx = [path_to_idx[p] for p in full_val_paths if p in path_to_idx]

        # è°ƒè¯•è¾“å‡º
        print(f"\nFold {fold_idx + 1} è·¯å¾„åŒ¹é…æƒ…å†µ:")
        print(f"  è¯·æ±‚çš„è®­ç»ƒå›¾åƒæ•°: {len(full_train_paths)}")
        print(f"  æˆåŠŸæ˜ å°„çš„è®­ç»ƒå›¾åƒæ•°: {len(train_idx)}")
        print(f"  è¯·æ±‚çš„éªŒè¯å›¾åƒæ•°: {len(full_val_paths)}")
        print(f"  æˆåŠŸæ˜ å°„çš„éªŒè¯å›¾åƒæ•°: {len(val_idx)}")

        if len(train_idx) == 0 or len(val_idx) == 0:
            raise ValueError(f"Fold {fold_idx + 1} çš„è®­ç»ƒæˆ–éªŒè¯é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è·¯å¾„ä¸€è‡´æ€§")

        fold_data.append({
            'train_idx': train_idx,
            'val_idx': val_idx,
            'mean': mean,
            'std': std
        })

    logging.info(f"âœ… æˆåŠŸåŠ è½½ {len(fold_data)} æŠ˜åˆ’åˆ†ï¼ˆå« mean/stdï¼‰")

    # ================================
    # å¼€å§‹ K-Fold è®­ç»ƒ
    # ================================
    fold_results = []

    for fold, data in enumerate(fold_data, start=1):
        print(f"\n========== Fold {fold}/{len(fold_data)} ==========")
        train_idx = data['train_idx']
        val_idx = data['val_idx']
        mean = data['mean']
        std = data['std']

        logging.info(f"Fold {fold} - mean: {mean}, std: {std}")

        # æ•°æ®å¢žå¼ºä¸Žå½’ä¸€åŒ–
        data_transform_train = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])
        data_transform_val = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])

        # æž„å»ºæ•°æ®é›†
        train_dataset = datasets.ImageFolder(root=dataset_root, transform=data_transform_train)
        val_dataset = datasets.ImageFolder(root=dataset_root, transform=data_transform_val)

        train_subset = Subset(train_dataset, train_idx)
        val_subset = Subset(val_dataset, val_idx)

        train_loader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
        val_loader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)

        # æž„å»ºæ¨¡åž‹
        model_class = MODEL_MAP[args.model_type]
        model_kwargs = {}

        if args.model_type == 'edge_enhanced':
            model_kwargs.update({
                'edge_layer_idx': args.edge_layer_idx,
                'fusion_levels': args.fusion_levels,
                'edge_attention': args.edge_attention,
                'fusion_mode': args.fusion_mode,
            })
        elif args.model_type in ['dual_branch', 'dual_branch_enhanced']:
            model_kwargs.update({
                'fusion_levels': args.fusion_levels,
                'edge_attention': args.edge_attention,
                'fusion_mode': args.fusion_mode,
            })

        net = model_class(
            depths=[2, 2, 4, 2],
            dims=[96, 192, 384, 768],
            num_classes=args.num_classes,
            **model_kwargs
        ).to(device)

        loss_function = nn.CrossEntropyLoss()
        optimizer = optim.Adam(net.parameters(), lr=5e-4)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs // 2)

        best_metrics = None
        fold_save_path = base_save_path.replace("_best.pth", f"_fold{fold}_best.pth")

        for epoch in range(args.epochs):
            # è®­ç»ƒ
            net.train()
            running_loss = 0.0
            train_bar = tqdm(train_loader, file=sys.stdout, desc=f"Epoch [{epoch + 1}/{args.epochs}] Training")
            for step, (images, labels) in enumerate(train_bar):
                images = images.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()
                outputs = net(images)
                loss = loss_function(outputs, labels)
                loss.backward()
                optimizer.step()

                running_loss += loss.item()
                train_bar.set_postfix(loss=f"{loss.item():.3f}")

            # æ›´æ–°å­¦ä¹ çŽ‡
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']

            # éªŒè¯ï¼ˆå¤šæŒ‡æ ‡ï¼‰
            metrics = evaluate_with_metrics(net, val_loader, device, args.num_classes)

            log_msg = (f"[Fold {fold}][Epoch {epoch + 1}/{args.epochs}] "
                       f"Loss: {running_loss / len(train_loader):.3f} | "
                       f"Acc: {metrics['acc']:.4f} | "
                       f"Precision: {metrics['precision']:.4f} | "
                       f"Recall: {metrics['recall']:.4f} | "
                       f"F1: {metrics['f1']:.4f} | "
                       f"LR: {current_lr:.2e}")
            print(log_msg)
            logging.info(log_msg)

            # ä¿å­˜æœ€ä½³æ¨¡åž‹ï¼ˆä»¥ Accuracy ä¸ºå‡†ï¼‰
            if best_metrics is None or metrics['acc'] > best_metrics['acc']:
                best_metrics = metrics.copy()
                torch.save(net.state_dict(), fold_save_path)
                logging.info(f"âœ… Saved best model (Acc: {metrics['acc']:.4f}) to {fold_save_path}")

        # è®°å½•æœ¬æŠ˜æœ€ä½³æŒ‡æ ‡
        fold_results.append(best_metrics)
        print(f"ðŸ“Œ Fold {fold} Best Metrics: {best_metrics}")

    # ================================
    # æ±‡æ€»ç»“æžœ
    # ================================
    all_acc = [r['acc'] for r in fold_results]
    all_prec = [r['precision'] for r in fold_results]
    all_rec = [r['recall'] for r in fold_results]
    all_f1 = [r['f1'] for r in fold_results]

    summary = {
        "Average Accuracy": float(np.mean(all_acc)),
        "Std Accuracy": float(np.std(all_acc)),
        "Average Precision": float(np.mean(all_prec)),
        "Average Recall": float(np.mean(all_rec)),
        "Average F1": float(np.mean(all_f1)),
        "Per-fold Results": [
            {
                "fold": i + 1,
                "acc": r['acc'],
                "precision": r['precision'],
                "recall": r['recall'],
                "f1": r['f1']
            }
            for i, r in enumerate(fold_results)
        ]
    }

    print("\n========== Cross-Validation Results ==========")
    for k, v in summary.items():
        if k != "Per-fold Results":
            print(f"{k}: {v:.4f}" if isinstance(v, float) else f"{k}: {v}")

    summary_path = os.path.join(log_dir, "cv_summary.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=4, ensure_ascii=False)

    logging.info(f"âœ… CV Summary saved to: {summary_path}")
    logging.info("âœ… Training completed.")


if __name__ == '__main__':
    main()