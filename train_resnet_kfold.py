# -*- coding: utf-8 -*-
import os
import sys
import json
import time
import argparse
import logging
import random
import numpy as np
import pickle
from collections import defaultdict

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from torchvision import transforms, datasets, models
from tqdm import tqdm
from sklearn.metrics import precision_recall_fscore_support, accuracy_score


# ========== Utils ==========
def seed_everything(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def setup_logger_and_saver(model_name="resnet50"):
    current_time = time.strftime("%Y%m%d-%H%M%S")
    log_dir = os.path.join("../logs", current_time)
    os.makedirs(log_dir, exist_ok=True)

    log_file = os.path.join(log_dir, "log.txt")
    model_save_path = os.path.join(log_dir, f"{model_name}_best.pth")

    logging.basicConfig(
        level=logging.INFO,
        format="[%(asctime)s][%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout),
        ],
    )
    logging.info(f"Logging to: {log_file}")
    logging.info(f"Best model (per fold) will be saved under: {log_dir}")
    return log_dir, model_save_path


def build_model(model_name: str, num_classes: int = 2):
    """
    ä»…æ”¯æŒï¼š
    - ResNet: resnet18, resnet34, resnet101
    - ConvNeXt: convnext_t, convnext_s, convnext_b   (æ˜ å°„åˆ° tiny/small/base)
    - EfficientNet: efficientnet_b3, efficientnet_b4, efficientnet_b6
    - DenseNet: densenet169, densenet201, densenet161
    - ViT: vit_t, vit_s, vit_b                        (é€šè¿‡ timm: tiny/small/base)
    - Swin: swin_t, swin_s, swin_b
    """
    from torchvision import models as tvm

    # --- ViT(t/s/b) ç”¨ timmï¼Œé¿å…æ‰‹åŠ¨æ”¹ classifier ---
    TIMM_VIT_NAMES = {
        'vit_t': 'vit_tiny_patch16_224',
        'vit_s': 'vit_small_patch16_224',
        'vit_b': 'vit_base_patch16_224',
    }
    if model_name in TIMM_VIT_NAMES:
        try:
            import timm
        except Exception as e:
            raise ImportError("ä½¿ç”¨ vit_t/vit_s/vit_b éœ€è¦å®‰è£… timmï¼š pip install timm") from e
        model = timm.create_model(TIMM_VIT_NAMES[model_name], pretrained=False, num_classes=num_classes)
        return model

    # å…¶ä½™å‹å·å‡ç”¨ torchvision
    model_map = {
        # -------- ResNet ----------
        'resnet18':  tvm.resnet18,
        'resnet34':  tvm.resnet34,
        'resnet101': tvm.resnet101,

        # -------- ConvNeXt (t/s/b -> tiny/small/base) ----------
        'convnext_t': tvm.convnext_tiny,
        'convnext_s': tvm.convnext_small,
        'convnext_b': tvm.convnext_base,

        # -------- EfficientNet ----------
        'efficientnet_b3': tvm.efficientnet_b3,
        'efficientnet_b4': tvm.efficientnet_b4,
        'efficientnet_b6': tvm.efficientnet_b6,

        # -------- DenseNet ----------
        'densenet169': tvm.densenet169,
        'densenet201': tvm.densenet201,
        'densenet161': tvm.densenet161,

        # -------- Swin ----------
        'swin_t': tvm.swin_t,
        'swin_s': tvm.swin_s,
        'swin_b': tvm.swin_b,
    }

    if model_name not in model_map:
        raise ValueError(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")

    # ä¸åŠ è½½é¢„è®­ç»ƒ
    model = model_map[model_name](weights=None)

    # --- ç»Ÿä¸€æ›¿æ¢åˆ†ç±»å¤´ä¸º num_classes ---
    if hasattr(model, 'fc') and isinstance(model.fc, nn.Linear):
        # ResNet
        in_features = model.fc.in_features
        model.fc = nn.Linear(in_features, num_classes)

    elif hasattr(model, 'classifier'):
        # ConvNeXt / EfficientNet / DenseNetï¼ˆéƒ½æœ‰ classifierï¼‰
        if isinstance(model.classifier, nn.Sequential):
            # ConvNeXtã€EfficientNetï¼šæœ€åä¸€å±‚æ˜¯ Linear
            last = model.classifier[-1]
            if isinstance(last, nn.Linear):
                in_features = last.in_features
                model.classifier[-1] = nn.Linear(in_features, num_classes)
            else:
                # å…œåº•ï¼šç›´æ¥æ›¿æ¢æ•´ä¸ª classifier
                in_features = getattr(last, 'in_features', None)
                if in_features is None and hasattr(model, 'num_features'):
                    in_features = model.num_features
                if in_features is None:
                    raise NotImplementedError(f"æ— æ³•ç¡®å®š {model_name} çš„åˆ†ç±»å¤´è¾“å…¥ç»´åº¦")
                model.classifier = nn.Sequential(nn.Flatten(), nn.Linear(in_features, num_classes))
        else:
            # DenseNet: classifier æ˜¯ Linear
            if isinstance(model.classifier, nn.Linear):
                in_features = model.classifier.in_features
                model.classifier = nn.Linear(in_features, num_classes)
            else:
                raise NotImplementedError(f"æœªå®ç° {model_name} çš„ classifier æ›¿æ¢")

    elif hasattr(model, 'heads') and hasattr(model.heads, 'head'):
        # Swinï¼ˆtorchvisionï¼‰
        in_features = model.heads.head.in_features
        model.heads.head = nn.Linear(in_features, num_classes)

    else:
        raise NotImplementedError(f"âŒ æœªå®ç°åˆ†ç±»å¤´æ›¿æ¢é€»è¾‘: {model_name}")

    return model



# ========== Evaluate (Multi-metric) ==========
@torch.no_grad()
def evaluate_with_metrics(model, loader, device, num_classes):
    """
    è¿”å› Accuracy, Precision, Recall, F1
    """
    model.eval()
    all_preds = []
    all_labels = []

    pbar = tqdm(loader, desc="Evaluating", leave=False, file=sys.stdout)
    for images, labels in pbar:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        preds = outputs.argmax(dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

    # è½¬ä¸º numpy
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)

    # Accuracy
    acc = accuracy_score(all_labels, all_preds)

    # Precision, Recall, F1 (macro average for multi-class)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_labels, all_preds, average='macro', zero_division=0
    )

    return {
        'acc': acc,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }


# ========== Train One Epoch ==========
def train_one_epoch(model, loader, device, optimizer, loss_fn):
    model.train()
    running_loss = 0.0
    pbar = tqdm(loader, desc="Training", leave=False, file=sys.stdout)
    for images, labels in pbar:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        pbar.set_postfix(loss=f"{loss.item():.4f}")

    return running_loss / max(1, len(loader))


# ========== Main ==========
def main():
    parser = argparse.ArgumentParser(description="Train ResNet/ConvNeXt/ViT/Swin with 5-Fold Cross Validation")
    parser.add_argument("--dataset", type=str, default="å•ä¸ªç»†èƒåˆ†ç±»æ•°æ®é›†äºŒåˆ†ç±»S2L", help="ImageFolder æ ¹ç›®å½•åï¼ˆæŒ‚è½½åœ¨ /data ä¸‹ï¼‰")
    parser.add_argument("--num_classes", type=int, default=2)
    parser.add_argument("--epochs", type=int, default=100)
    parser.add_argument("--batch_size", type=int, default=16)
    parser.add_argument("--lr", type=float, default=5e-5)
    parser.add_argument("--num_workers", type=int, default=4)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument(
        "--model_name",
        type=str,
        default="resnet34",
        choices=[
            # ResNet
            'resnet18', 'resnet34', 'resnet101',
            # ConvNeXt
            'convnext_t', 'convnext_s', 'convnext_b',
            # EfficientNet
            'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b6',
            # DenseNet
            'densenet169', 'densenet201', 'densenet161',
            # ViT (timm)
            'vit_t', 'vit_s', 'vit_b',
            # Swin
            'swin_t', 'swin_s', 'swin_b',
        ],
        help="é€‰æ‹©æ¨¡å‹ï¼ˆé»˜è®¤ resnet34ï¼‰"
    )

    parser.add_argument('--early_stop', type=int, default=10)

    args = parser.parse_args()
    seed_everything(args.seed)

    # æ—¥å¿—ä¸ä¿å­˜
    log_dir, base_save_path = setup_logger_and_saver(args.model_name)
    config_path = os.path.join(log_dir, "config.json")
    with open(config_path, "w") as f:
        json.dump(vars(args), f, indent=4, ensure_ascii=False)
    logging.info(f"Training parameters saved to: {config_path}")

    # è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # æ•°æ®é›†è·¯å¾„
    dataset_root = f"/data/{args.dataset}"
    full_dataset = datasets.ImageFolder(root=dataset_root, transform=None)
    logging.info(f"Loaded dataset from: {dataset_root}, total samples: {len(full_dataset)}")

    # ================================
    # ğŸš€ åŠ è½½ kfold_splits.pklï¼ˆåŒ…å« mean/stdï¼‰
    # ================================
    kfold_pkl_path = os.path.join(dataset_root, "kfold_splits.pkl")
    if not os.path.exists(kfold_pkl_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°åˆ’åˆ†æ–‡ä»¶: {kfold_pkl_path}\nè¯·å…ˆè¿è¡Œåˆ’åˆ†ç”Ÿæˆè„šæœ¬ã€‚")

    logging.info(f"âœ… åŠ è½½åˆ’åˆ†æ–‡ä»¶: {kfold_pkl_path}")
    with open(kfold_pkl_path, 'rb') as f:
        data = pickle.load(f)

    splits = data['splits']
    fold_data = []

    # âœ… æ„å»ºå®Œæ•´è·¯å¾„ â†’ ç´¢å¼• æ˜ å°„
    path_to_idx = {
        os.path.join(dataset_root, img_path).replace("\\", "/").replace("//", "/"): idx
        for idx, (img_path, _) in enumerate(full_dataset.imgs)
    }

    for fold_idx, split in enumerate(splits):
        rel_train_paths = split['train']
        rel_val_paths = split['val']
        mean = split['mean']
        std = split['std']

        # âœ… æ‹¼æ¥å®Œæ•´è·¯å¾„
        full_train_paths = [
            os.path.join(dataset_root, p).replace("\\", "/") for p in rel_train_paths
        ]
        full_val_paths = [
            os.path.join(dataset_root, p).replace("\\", "/") for p in rel_val_paths
        ]

        # æ˜ å°„åˆ°ç´¢å¼•
        train_idx = [path_to_idx[p] for p in full_train_paths if p in path_to_idx]
        val_idx = [path_to_idx[p] for p in full_val_paths if p in path_to_idx]

        # è°ƒè¯•è¾“å‡º
        print(f"\nFold {fold_idx + 1} è·¯å¾„åŒ¹é…æƒ…å†µ:")
        print(f"  è¯·æ±‚çš„è®­ç»ƒå›¾åƒæ•°: {len(full_train_paths)}")
        print(f"  æˆåŠŸæ˜ å°„çš„è®­ç»ƒå›¾åƒæ•°: {len(train_idx)}")
        print(f"  è¯·æ±‚çš„éªŒè¯å›¾åƒæ•°: {len(full_val_paths)}")
        print(f"  æˆåŠŸæ˜ å°„çš„éªŒè¯å›¾åƒæ•°: {len(val_idx)}")

        if len(train_idx) == 0 or len(val_idx) == 0:
            raise ValueError(f"Fold {fold_idx + 1} çš„è®­ç»ƒæˆ–éªŒè¯é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è·¯å¾„ä¸€è‡´æ€§")

        fold_data.append({
            'train_idx': train_idx,
            'val_idx': val_idx,
            'mean': mean,
            'std': std
        })

    logging.info(f"âœ… æˆåŠŸåŠ è½½ {len(fold_data)} æŠ˜åˆ’åˆ†ï¼ˆå« mean/stdï¼‰")

    # ================================
    # å¼€å§‹ K-Fold è®­ç»ƒ
    # ================================
    fold_results = []

    for fold, data in enumerate(fold_data, start=1):
        print(f"\n========== Fold {fold}/{len(fold_data)} ==========")
        train_idx = data['train_idx']
        val_idx = data['val_idx']
        mean = data['mean']
        std = data['std']

        logging.info(f"Fold {fold} - mean: {mean}, std: {std}")

        # æ•°æ®å¢å¼ºä¸å½’ä¸€åŒ–ï¼ˆç»Ÿä¸€ 224x224ï¼‰
        data_transform_train = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.5),  # ğŸ‘ˆ åŠ å‚ç›´ç¿»è½¬
            transforms.RandomRotation(degrees=15),  # ğŸ‘ˆ åŠ æ—‹è½¬
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])
        data_transform_val = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std),
        ])


        # æ„å»ºæ•°æ®é›†
        train_dataset = datasets.ImageFolder(root=dataset_root, transform=data_transform_train)
        val_dataset = datasets.ImageFolder(root=dataset_root, transform=data_transform_val)

        train_subset = Subset(train_dataset, train_idx)
        val_subset = Subset(val_dataset, val_idx)

        train_loader = DataLoader(train_subset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)
        val_loader = DataLoader(val_subset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)

        # æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æŸå¤±
        model = build_model(args.model_name, num_classes=args.num_classes).to(device)

        # ğŸ’¡ æ‰“å°å‚æ•°é‡ï¼ˆæœ¬åœ°è®¡ç®—ï¼Œæ—  thop ä¾èµ–ï¼‰
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ… ä½¿ç”¨æ¨¡å‹: {args.model_name} | æ€»å‚æ•°é‡: {total_params / 1e6:.2f}M")

        optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=0.01)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)
        loss_fn = nn.CrossEntropyLoss()

        best_metrics = None
        fold_save_path = base_save_path.replace("_best.pth", f"_fold{fold}_best.pth")
        best_acc = -float('inf')
        epochs_no_improve = 0

        for epoch in range(1, args.epochs + 1):
            avg_loss = train_one_epoch(model, train_loader, device, optimizer, loss_fn)
            metrics = evaluate_with_metrics(model, val_loader, device, args.num_classes)
            scheduler.step()

            current_lr = optimizer.param_groups[0]['lr']
            log_msg = (f"[Fold {fold}][Epoch {epoch}/{args.epochs}] "
                       f"Loss: {avg_loss:.4f} | "
                       f"Acc: {metrics['acc']:.4f} | "
                       f"Precision: {metrics['precision']:.4f} | "
                       f"Recall: {metrics['recall']:.4f} | "
                       f"F1: {metrics['f1']:.4f} | "
                       f"LR: {current_lr:.2e}")
            print(log_msg)
            logging.info(log_msg)

            # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆä»¥ Accuracy ä¸ºæ ‡å‡†ï¼‰
            improved = metrics['acc'] > best_acc
            if best_metrics is None or improved:
                best_acc = metrics['acc']
                best_metrics = metrics.copy()
                epochs_no_improve = 0
                torch.save(model.state_dict(), fold_save_path)
                logging.info(f"âœ… Saved best model (Acc: {metrics['acc']:.4f}) to {fold_save_path}")
            else:
                epochs_no_improve += 1
                if epochs_no_improve >= args.early_stop:
                    logging.info(f"â¹ Early stopping on fold {fold} at epoch {epoch}")
                    break

        # è®°å½•æœ¬æŠ˜æœ€ä½³æŒ‡æ ‡
        fold_results.append(best_metrics)
        print(f"ğŸ“Œ Fold {fold} Best Metrics: {best_metrics}")

    all_acc = [r['acc'] for r in fold_results]
    all_prec = [r['precision'] for r in fold_results]
    all_rec = [r['recall'] for r in fold_results]
    all_f1 = [r['f1'] for r in fold_results]

    # æ„å»º summaryï¼ˆä¸åŒ…å« FLOPsï¼‰
    summary = {
        "Model Name": args.model_name,
        "Model Parameters (M)": round(total_params / 1e6, 3),  # ä½¿ç”¨æœ€åä¸€æ¬¡æ„å»ºçš„æ¨¡å‹å‚æ•°é‡
        "Average Accuracy": float(np.mean(all_acc)),
        "Std Accuracy": float(np.std(all_acc)),
        "Average Precision": float(np.mean(all_prec)),
        "Std Precision": float(np.std(all_prec)),
        "Average Recall": float(np.mean(all_rec)),
        "Std Recall": float(np.std(all_rec)),
        "Average F1": float(np.mean(all_f1)),
        "Std F1": float(np.std(all_f1)),
        "Per-fold Results": [
            {
                "fold": i + 1,
                "acc": r['acc'],
                "precision": r['precision'],
                "recall": r['recall'],
                "f1": r['f1']
            }
            for i, r in enumerate(fold_results)
        ]
    }

    print("\n========== Cross-Validation Results ==========")
    for k, v in summary.items():
        if k != "Per-fold Results" and isinstance(v, float):
            print(f"{k}: {v:.4f}")
        elif k != "Per-fold Results":
            print(f"{k}: {v}")

    summary_path = os.path.join(log_dir, "cv_summary.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=4, ensure_ascii=False)

    logging.info(f"âœ… CV Summary saved to: {summary_path}")
    logging.info("âœ… Training completed.")


if __name__ == "__main__":
    main()